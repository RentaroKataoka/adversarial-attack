{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def torch_fix_seed(seed=42):\n",
    "    # Python random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms = True\n",
    "\n",
    "torch_fix_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.0.0+cu117\n",
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print('torch version:',torch.__version__)\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset loading\n",
    "class ImageTransform():\n",
    "    def __init__(self, mean, std):\n",
    "        self.data_transform = transforms.Compose([\n",
    "        transforms.Grayscale(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.Normalize(mean, std)\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.data_transform(img)\n",
    "mean = (0.5,)\n",
    "std = (0.5,)\n",
    "test_images = ImageFolder( \"../data/unet_test\", transform = ImageTransform(mean, std))\n",
    "test_loader = DataLoader(test_images, batch_size = 1, shuffle = False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv9 = nn.Conv2d(512, 1024, 3, padding=1)\n",
    "        self.conv10 = nn.Conv2d(1024, 1024, 3, padding=1)\n",
    "        self.conv11 = nn.Conv2d(1024, 512, 2, padding=\"same\")\n",
    "        self.conv12 = nn.Conv2d(1024, 512, 3, padding=1)\n",
    "        self.conv13 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv14 = nn.Conv2d(512, 256, 2, padding=\"same\")\n",
    "        self.conv15 = nn.Conv2d(512, 256, 3, padding=1)\n",
    "        self.conv16 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv17 = nn.Conv2d(256, 128, 2, padding=\"same\")\n",
    "        self.conv18 = nn.Conv2d(256, 128, 3, padding=1)\n",
    "        self.conv19 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv20 = nn.Conv2d(128, 64, 2, padding=\"same\")\n",
    "        self.conv21 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.conv22 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv23 = nn.Conv2d(64, 2, 3, padding=1)\n",
    "        self.conv24 = nn.Conv2d(2, 1, 1)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "        # # self.label_emb = nn.Embedding(class_num, class_num)\n",
    "        \n",
    "        # self.model = nn.Sequential(\n",
    "        #     nn.Conv2d(1, 64, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Conv2d(64, 64, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.MaxPool2d(2),\n",
    "        #     nn.Conv2d(64, 128, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Conv2d(128, 128, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.MaxPool2d(2),\n",
    "        #     nn.Conv2d(128, 256, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Conv2d(256, 256, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.MaxPool2d(2),\n",
    "        #     nn.Conv2d(256, 512, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Conv2d(512, 512, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Dropout(0.5),\n",
    "        #     nn.MaxPool2d(2),\n",
    "        #     nn.Conv2d(512, 1024, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Conv2d(1024, 1024, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Dropout(0.5),\n",
    "        #     nn.Conv2d(1024, 512, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "\n",
    "\n",
    "        #     nn.ConvTranspose2d(self.z_size + 26, ngf * 32, 4, 1, 0, bias=False),\n",
    "        #     nn.BatchNorm2d(ngf * 32),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.ConvTranspose2d(ngf * 32, ngf * 16, 4, 2, 1, bias=False),\n",
    "        #     nn.BatchNorm2d(ngf * 16),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.ConvTranspose2d(ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n",
    "        #     nn.BatchNorm2d(ngf * 8),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "        #     nn.BatchNorm2d(ngf * 4),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "        #     nn.BatchNorm2d(ngf * 2),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.ConvTranspose2d(ngf * 2, ngf, 3, 1, 1, bias=False),\n",
    "        #     nn.BatchNorm2d(ngf),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.ConvTranspose2d(ngf, 1, 3, 1, 1, bias=False),\n",
    "        #     nn.Tanh()\n",
    "        # )\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        conv1 = self.conv1(x)\n",
    "        conv1 = self.relu(conv1)\n",
    "        conv1 = self.conv2(conv1)\n",
    "        conv1 = self.relu(conv1)\n",
    "        pool1 = self.maxpool(conv1)\n",
    "        conv2 = self.conv3(pool1)\n",
    "        conv2 = self.relu(conv2)\n",
    "        conv2 = self.conv4(conv2)\n",
    "        conv2 = self.relu(conv2)\n",
    "        pool2  =self.maxpool(conv2)\n",
    "        conv3 = self.conv5(pool2)\n",
    "        conv3 = self.relu(conv3)\n",
    "        conv3 = self.conv6(conv3)\n",
    "        conv3 = self.relu(conv3)\n",
    "        pool3 = self.maxpool(conv3)\n",
    "        conv4 = self.conv7(pool3)\n",
    "        conv4 = self.relu(conv4)\n",
    "        conv4 = self.conv8(conv4)\n",
    "        conv4 = self.relu(conv4)\n",
    "        drop4 = self.dropout(conv4)\n",
    "        pool4 = self.maxpool(drop4)\n",
    "        conv5 = self.conv9(pool4)\n",
    "        conv5 = self.relu(conv5)\n",
    "        conv5 = self.conv10(conv5)\n",
    "        conv5 = self.relu(conv5)\n",
    "        drop5 = self.dropout(conv5)\n",
    "        up6 = self.up(drop5)\n",
    "        up6 = self.conv11(up6)\n",
    "        up6 = self.relu(up6)\n",
    "        merge6 = torch.cat((drop4, up6), 1)\n",
    "        conv6 = self.conv12(merge6)\n",
    "        conv6 = self.relu(conv6)\n",
    "        conv6 = self.conv13(conv6)\n",
    "        conv6 = self.relu(conv6)\n",
    "        up7 = self.up(conv6)\n",
    "        up7 = self.conv14(up7)\n",
    "        up7 = self.relu(up7)\n",
    "        merge7 = torch.cat((conv3, up7), 1)\n",
    "        conv7 = self.conv15(merge7)\n",
    "        conv7 = self.relu(conv7)\n",
    "        conv7 = self.conv16(conv7)\n",
    "        conv7 = self.relu(conv7)\n",
    "        up8 = self.up(conv7)\n",
    "        up8 = self.conv17(up8)\n",
    "        up8 = self.relu(up8)\n",
    "        merge8 = torch.cat((conv2, up8), 1)\n",
    "        conv8 = self.conv18(merge8)\n",
    "        conv8 = self.relu(conv8)\n",
    "        conv8 = self.conv19(conv8)\n",
    "        conv8 = self.relu(conv8)\n",
    "        up9 = self.up(conv8)\n",
    "        up9 = self.conv20(up9)\n",
    "        up9 = self.relu(up9)\n",
    "        merge9 = torch.cat((conv1, up9), 1)\n",
    "        conv9 = self.conv21(merge9)\n",
    "        conv9 = self.relu(conv9)\n",
    "        conv9 = self.conv22(conv9)\n",
    "        conv9 = self.relu(conv9)\n",
    "        conv9 = self.conv23(conv9)\n",
    "        conv9 = self.relu(conv9)\n",
    "        conv10 = self.conv24(conv9)\n",
    "        output = self.tanh(conv10)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = \"../model/googlefonts.pth\" #事前学習済みMNISTモデル(重みパラメータ)\n",
    "use_cuda = True\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(57600, 128)\n",
    "        self.fc2 = nn.Linear(128, 26)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "# 使うデバイス（CPUかGPUか）の定義\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "# ネットワークの初期化\n",
    "model1 = Net().to(device)\n",
    "# 訓練済みモデルのロード\n",
    "model1.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "# モデルを評価モードに設定。本チュートリアルの例では、これはドロップアウト層等を評価モードにするのに必要\n",
    "model1.eval()\n",
    "model2 = Net().to(device)\n",
    "# 訓練済みモデルのロード\n",
    "model2.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "# モデルを評価モードに設定。本チュートリアルの例では、これはドロップアウト層等を評価モードにするのに必要\n",
    "model2.eval()\n",
    "\n",
    "for param in model1.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model2.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv7): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv9): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv10): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv11): Conv2d(1024, 512, kernel_size=(2, 2), stride=(1, 1), padding=same)\n",
       "  (conv12): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv14): Conv2d(512, 256, kernel_size=(2, 2), stride=(1, 1), padding=same)\n",
       "  (conv15): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv17): Conv2d(256, 128, kernel_size=(2, 2), stride=(1, 1), padding=same)\n",
       "  (conv18): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv19): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv20): Conv2d(128, 64, kernel_size=(2, 2), stride=(1, 1), padding=same)\n",
       "  (conv21): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv22): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv23): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv24): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (tanh): Tanh()\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet = Unet().to(device)\n",
    "unet.load_state_dict(torch.load(\"../defensive_unet.pth\", map_location=\"cpu\"))\n",
    "unet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack(data, data_grad, target, model, dirname_res, dirname_pro, chr, count, epsilon, lim, success):\n",
    "    os.makedirs(dirname_pro + chr + \"/{}\".format(count), exist_ok=True)\n",
    "    # os.makedirs(dirname_pro + chr + \"/{}\".format(i), exist_ok=True)\n",
    "    for i in range(1, 1001):\n",
    "        data.requires_grad = False\n",
    "        sign_data_grad = data_grad.sign()\n",
    "        perturbed_data = data + epsilon * sign_data_grad\n",
    "        # perturbed_data += (perturbed_data < torch.Tensor([1 - lim]).to(\"cuda\")) * epsilon + (perturbed_data < torch.Tensor([0]).to(\"cuda\")) * -epsilon + (perturbed_data > torch.Tensor([-1 + lim]).to(\"cuda\")) * -epsilon + (perturbed_data > torch.Tensor([0]).to(\"cuda\")) * epsilon\n",
    "        perturbed_data = torch.clamp(perturbed_data, -1, 1)\n",
    "        data = perturbed_data\n",
    "        data.requires_grad = True\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        if pred.item() != target.item():\n",
    "            success += 1\n",
    "            break\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        data_grad = data.grad.data\n",
    "    return data, pred, success, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    chr_lambda = lambda a: chr(a + 65)\n",
    "    dirname_grad = \"../unet_attack_result\" + \"/grad/\"\n",
    "    dirname_org = \"../unet_attack_result\" + \"/org/\"\n",
    "    dirname_adv = \"../unet_attack_result\" + \"/adv/\"\n",
    "    dirname_res = \"../unet_attack_result\" + \"/resistance/\"\n",
    "    dirname_pro = \"../unet_attack_result\" + \"/progress/\"\n",
    "    for c in [chr(i) for i in range(65, 65+26)]:\n",
    "        os.makedirs(dirname_grad + c, exist_ok=True)\n",
    "        os.makedirs(dirname_org + c, exist_ok=True)\n",
    "        os.makedirs(dirname_adv + c, exist_ok=True)\n",
    "        os.makedirs(dirname_res + c, exist_ok=True)\n",
    "        os.makedirs(dirname_pro + c, exist_ok=True)\n",
    "        for d in [chr(i) for i in range(65, 65+26)]:\n",
    "            os.makedirs(dirname_adv + c + \"/\" + c + \"→\" + d, exist_ok=True)\n",
    "\n",
    "    # 精度カウンター\n",
    "    success = 0\n",
    "    # count = 0\n",
    "    count_list = [0] * 26\n",
    "\n",
    "    # テスト用データセット内の全てのサンプルをループします\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "\n",
    "        # データとラベルをデバイス（CPUもしくはGPU）に送信します\n",
    "        data, target = Variable(data).to(device), Variable(target.to(device))\n",
    "        generated = unet(data).detach()\n",
    "        generated = Variable(generated).to(device)\n",
    "        # data = generated.unsqueeze(0).to(device)\n",
    "        # テンソルの requires_grad 属性を設定します。攻撃者にとっては重要な設定です。\n",
    "\n",
    "        data.requires_grad = True\n",
    "        generated.requires_grad = True\n",
    "        # データをモデルに順伝播させます\n",
    "        output1 = model1(data)\n",
    "        output2 = model2(generated)\n",
    "        init_pred = output1.max(1, keepdim=True)[1] # 最大の確率のインデックスを取得します。\n",
    "\n",
    "        # 最初から予測が間違っている場合、攻撃する必要がないため次のイテレーションに進みます。\n",
    "        \n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        data_copy = data.detach().clone()\n",
    "        # character_coordinate = character_search(data_copy.data[0][0])\n",
    "\n",
    "        count_list[init_pred.item()] += 1\n",
    "    \n",
    "        # 損失を計算します\n",
    "        loss1 = F.nll_loss(output1, target)\n",
    "        loss2 = F.nll_loss(output2, target)\n",
    "        # 既存の勾配を全てゼロにします\n",
    "        model1.zero_grad()\n",
    "        model2.zero_grad()\n",
    "        # 逆伝播させてモデルの勾配を計算します\n",
    "        loss1.backward()\n",
    "        loss2.backward()\n",
    "        # データの勾配を取得します\n",
    "        data_grad = data.grad.data\n",
    "        generated_grad = generated.grad.data\n",
    "        \n",
    "        # # 勾配のヒートマップ\n",
    "        # grad_map = data_grad.squeeze().detach().cpu().numpy()\n",
    "        # grad_map_abs = np.abs(grad_map)\n",
    "        # plt.xticks([], [])\n",
    "        # plt.yticks([], [])\n",
    "        # plt.imsave(dirname_grad + chr_lambda(init_pred.item()) + \"/{}.png\".format(count_list[init_pred.item()]), grad_map_abs, cmap=\"Reds\")\n",
    "\n",
    "        perturbed_data1, pred1, success1, count1 = attack(data, data_grad, target, model1,  dirname_res, dirname_pro, chr_lambda(init_pred.item()), count_list[init_pred.item()], 0.02, 0, success)\n",
    "        perturbed_data2, pred2, success2, count2 = attack(generated, generated_grad, target, model2,  dirname_res, dirname_pro, chr_lambda(init_pred.item()), count_list[init_pred.item()], 0.02, 0, success)\n",
    "\n",
    "        data = data.squeeze().detach().cpu().numpy()\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])  \n",
    "        plt.title(\"{}\".format(loss1.item()))\n",
    "        plt.imshow(data, cmap=\"gray\")\n",
    "        generated= generated.squeeze().detach().cpu().numpy()\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        plt.title(\"{}\".format(loss2.item()))\n",
    "        plt.imshow(generated, cmap=\"gray\")\n",
    "        plt.savefig(\"../sample/\" + \"{}.png\".format(i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoge/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/hoge/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1003.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
