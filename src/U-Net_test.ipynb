{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def torch_fix_seed(seed=42):\n",
    "    # Python random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms = True\n",
    "\n",
    "torch_fix_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.0.0+cu117\n",
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print('torch version:',torch.__version__)\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset loading\n",
    "class ImageTransform():\n",
    "    def __init__(self, mean, std):\n",
    "        self.data_transform = transforms.Compose([\n",
    "        transforms.Grayscale(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.Normalize(mean, std)\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.data_transform(img)\n",
    "mean = (0.5,)\n",
    "std = (0.5,)\n",
    "test_images = ImageFolder( \"../data/unet_test\", transform = ImageTransform(mean, std))\n",
    "test_loader = DataLoader(test_images, batch_size = 1, shuffle = False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv9 = nn.Conv2d(512, 1024, 3, padding=1)\n",
    "        self.conv10 = nn.Conv2d(1024, 1024, 3, padding=1)\n",
    "        self.conv11 = nn.Conv2d(1024, 512, 2, padding=\"same\")\n",
    "        self.conv12 = nn.Conv2d(1024, 512, 3, padding=1)\n",
    "        self.conv13 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv14 = nn.Conv2d(512, 256, 2, padding=\"same\")\n",
    "        self.conv15 = nn.Conv2d(512, 256, 3, padding=1)\n",
    "        self.conv16 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv17 = nn.Conv2d(256, 128, 2, padding=\"same\")\n",
    "        self.conv18 = nn.Conv2d(256, 128, 3, padding=1)\n",
    "        self.conv19 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv20 = nn.Conv2d(128, 64, 2, padding=\"same\")\n",
    "        self.conv21 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.conv22 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv23 = nn.Conv2d(64, 2, 3, padding=1)\n",
    "        self.conv24 = nn.Conv2d(2, 1, 1)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "        # # self.label_emb = nn.Embedding(class_num, class_num)\n",
    "        \n",
    "        # self.model = nn.Sequential(\n",
    "        #     nn.Conv2d(1, 64, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Conv2d(64, 64, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.MaxPool2d(2),\n",
    "        #     nn.Conv2d(64, 128, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Conv2d(128, 128, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.MaxPool2d(2),\n",
    "        #     nn.Conv2d(128, 256, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Conv2d(256, 256, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.MaxPool2d(2),\n",
    "        #     nn.Conv2d(256, 512, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Conv2d(512, 512, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Dropout(0.5),\n",
    "        #     nn.MaxPool2d(2),\n",
    "        #     nn.Conv2d(512, 1024, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Conv2d(1024, 1024, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Dropout(0.5),\n",
    "        #     nn.Conv2d(1024, 512, 3, padding=1),\n",
    "        #     nn.ReLU(True),\n",
    "\n",
    "\n",
    "        #     nn.ConvTranspose2d(self.z_size + 26, ngf * 32, 4, 1, 0, bias=False),\n",
    "        #     nn.BatchNorm2d(ngf * 32),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.ConvTranspose2d(ngf * 32, ngf * 16, 4, 2, 1, bias=False),\n",
    "        #     nn.BatchNorm2d(ngf * 16),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.ConvTranspose2d(ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n",
    "        #     nn.BatchNorm2d(ngf * 8),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "        #     nn.BatchNorm2d(ngf * 4),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "        #     nn.BatchNorm2d(ngf * 2),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.ConvTranspose2d(ngf * 2, ngf, 3, 1, 1, bias=False),\n",
    "        #     nn.BatchNorm2d(ngf),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.ConvTranspose2d(ngf, 1, 3, 1, 1, bias=False),\n",
    "        #     nn.Tanh()\n",
    "        # )\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        conv1 = self.conv1(x)\n",
    "        conv1 = self.relu(conv1)\n",
    "        conv1 = self.conv2(conv1)\n",
    "        conv1 = self.relu(conv1)\n",
    "        pool1 = self.maxpool(conv1)\n",
    "        conv2 = self.conv3(pool1)\n",
    "        conv2 = self.relu(conv2)\n",
    "        conv2 = self.conv4(conv2)\n",
    "        conv2 = self.relu(conv2)\n",
    "        pool2  =self.maxpool(conv2)\n",
    "        conv3 = self.conv5(pool2)\n",
    "        conv3 = self.relu(conv3)\n",
    "        conv3 = self.conv6(conv3)\n",
    "        conv3 = self.relu(conv3)\n",
    "        pool3 = self.maxpool(conv3)\n",
    "        conv4 = self.conv7(pool3)\n",
    "        conv4 = self.relu(conv4)\n",
    "        conv4 = self.conv8(conv4)\n",
    "        conv4 = self.relu(conv4)\n",
    "        drop4 = self.dropout(conv4)\n",
    "        pool4 = self.maxpool(drop4)\n",
    "        conv5 = self.conv9(pool4)\n",
    "        conv5 = self.relu(conv5)\n",
    "        conv5 = self.conv10(conv5)\n",
    "        conv5 = self.relu(conv5)\n",
    "        drop5 = self.dropout(conv5)\n",
    "        up6 = self.up(drop5)\n",
    "        up6 = self.conv11(up6)\n",
    "        up6 = self.relu(up6)\n",
    "        merge6 = torch.cat((drop4, up6), 1)\n",
    "        conv6 = self.conv12(merge6)\n",
    "        conv6 = self.relu(conv6)\n",
    "        conv6 = self.conv13(conv6)\n",
    "        conv6 = self.relu(conv6)\n",
    "        up7 = self.up(conv6)\n",
    "        up7 = self.conv14(up7)\n",
    "        up7 = self.relu(up7)\n",
    "        merge7 = torch.cat((conv3, up7), 1)\n",
    "        conv7 = self.conv15(merge7)\n",
    "        conv7 = self.relu(conv7)\n",
    "        conv7 = self.conv16(conv7)\n",
    "        conv7 = self.relu(conv7)\n",
    "        up8 = self.up(conv7)\n",
    "        up8 = self.conv17(up8)\n",
    "        up8 = self.relu(up8)\n",
    "        merge8 = torch.cat((conv2, up8), 1)\n",
    "        conv8 = self.conv18(merge8)\n",
    "        conv8 = self.relu(conv8)\n",
    "        conv8 = self.conv19(conv8)\n",
    "        conv8 = self.relu(conv8)\n",
    "        up9 = self.up(conv8)\n",
    "        up9 = self.conv20(up9)\n",
    "        up9 = self.relu(up9)\n",
    "        merge9 = torch.cat((conv1, up9), 1)\n",
    "        conv9 = self.conv21(merge9)\n",
    "        conv9 = self.relu(conv9)\n",
    "        conv9 = self.conv22(conv9)\n",
    "        conv9 = self.relu(conv9)\n",
    "        conv9 = self.conv23(conv9)\n",
    "        conv9 = self.relu(conv9)\n",
    "        conv10 = self.conv24(conv9)\n",
    "        output = self.tanh(conv10)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = \"../model/googlefonts.pth\" #事前学習済みMNISTモデル(重みパラメータ)\n",
    "use_cuda = True\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(57600, 128)\n",
    "        self.fc2 = nn.Linear(128, 26)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "# 使うデバイス（CPUかGPUか）の定義\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "# ネットワークの初期化\n",
    "model1 = Net().to(device)\n",
    "# 訓練済みモデルのロード\n",
    "model1.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "# モデルを評価モードに設定。本チュートリアルの例では、これはドロップアウト層等を評価モードにするのに必要\n",
    "model1.eval()\n",
    "model2 = Net().to(device)\n",
    "# 訓練済みモデルのロード\n",
    "model2.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "# モデルを評価モードに設定。本チュートリアルの例では、これはドロップアウト層等を評価モードにするのに必要\n",
    "model2.eval()\n",
    "\n",
    "for param in model1.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model2.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv7): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv9): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv10): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv11): Conv2d(1024, 512, kernel_size=(2, 2), stride=(1, 1), padding=same)\n",
       "  (conv12): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv14): Conv2d(512, 256, kernel_size=(2, 2), stride=(1, 1), padding=same)\n",
       "  (conv15): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv17): Conv2d(256, 128, kernel_size=(2, 2), stride=(1, 1), padding=same)\n",
       "  (conv18): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv19): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv20): Conv2d(128, 64, kernel_size=(2, 2), stride=(1, 1), padding=same)\n",
       "  (conv21): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv22): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv23): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv24): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (tanh): Tanh()\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet = Unet().to(device)\n",
    "unet.load_state_dict(torch.load(\"../model/unet2+defensive.pth\", map_location=\"cpu\"))\n",
    "unet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack(data, data_grad, target, model, dirname_res, dirname_pro, chr, count, epsilon, lim, success):\n",
    "    os.makedirs(dirname_pro + chr + \"/{}\".format(count), exist_ok=True)\n",
    "    # os.makedirs(dirname_pro + chr + \"/{}\".format(i), exist_ok=True)\n",
    "    for i in range(1, 1001):\n",
    "        data.requires_grad = False\n",
    "        sign_data_grad = data_grad.sign()\n",
    "        perturbed_data = data + epsilon * sign_data_grad\n",
    "        # perturbed_data += (perturbed_data < torch.Tensor([1 - lim]).to(\"cuda\")) * epsilon + (perturbed_data < torch.Tensor([0]).to(\"cuda\")) * -epsilon + (perturbed_data > torch.Tensor([-1 + lim]).to(\"cuda\")) * -epsilon + (perturbed_data > torch.Tensor([0]).to(\"cuda\")) * epsilon\n",
    "        perturbed_data = torch.clamp(perturbed_data, -1, 1)\n",
    "        data = perturbed_data\n",
    "        data.requires_grad = True\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        if pred.item() != target.item():\n",
    "            success += 1\n",
    "            break\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        data_grad = data.grad.data\n",
    "    return data, pred, success, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoge/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/hoge/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1003.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAELCAYAAABEYIWnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvJElEQVR4nO3deXxM9/4/8NdkMkkmK2KJyCCJ2HcS+65qqVBbaXtdqkXVpaqqlFKqlqrYaimqrqqrVHqrlqpWcVF77ZpaYmkIgsQSWd+/P/xyvufMTCaTCMF5PR+PPB6fcz6fOedzJvM5eeeznDGIiICIiIh0y6WgK0BEREQFi8EAERGRzjEYICIi0jkGA0RERDrHYICIiEjnGAwQERHpHIMBIiIinWMwQEREpHMMBoiIiHSOwQAREZHOPRHBQEpKCkaOHInAwECYzWbUq1cPP//8c46vGz9+PAwGg82Ph4eHTdn4+Hj07dsXxYsXh9lsRu3atbF69Wq7x92yZQtatGiBokWLolChQoiIiMDy5cs1ZZKTk9GvXz9UrVoVfn5+8Pb2Ro0aNTBr1iykpaXZHPPAgQN44YUXEBAQAG9vb1SvXh2zZ89GRkaGUua3336zez1ZP5MmTVLKfvXVV9mWu3Lliubcw4YNQ+3atVGkSBF4enqiUqVKGD9+PO7cuWO3nm3btoWvry98fHzQpk0b/PHHHzblPvnkE9SvXx/FihWDh4cHwsLC8Pbbb+PatWs2ZS9fvoz+/fsjODgYZrMZoaGheOedd5CQkGBTNjMzE/Pnz0fNmjVhNpvh7++Pli1b4vDhw0qZ7H7vWT87d+60OS4ApKWloXLlyjAYDJg+fbpN/unTp9GtWzcULlwYnp6eaNy4MbZu3WpTbtGiRWjWrBlKlCgBd3d3BAcHo2/fvoiNjbV7XspeXts+APz999/o0aMHChUqBF9fX3Tq1Alnz561W3bJkiWoVKmS8lmdM2eOTZk///wTw4YNQ8OGDeHh4QGDwWD3d5qbdpply5YtaNmyJfz8/ODj44M6depg1apVNuV++OEH1K5dGx4eHihdujTGjRuH9PR0TZnt27cjMjISFosFHh4eCAgIQNu2bbP93KempuKTTz5BxYoV4eHhgRIlSqBDhw64dOmSUmbfvn0YPHgwqlSpAi8vL5QuXRo9evRATEyM3WPOnTsXlSpVgru7O0qVKoV33nkHd+/etSnnbJsC8r/t7927F4MGDUKdOnVgMplgMBjsnhdw/u9D2bJlsz13WFiYUs7R/dlgMGDFihW5Pqa6rgMGDECpUqXg4eGBsmXLol+/ftlem7NcH/oI+aBPnz5Ys2YN3n77bYSFheGrr75C+/btsXXrVjRu3DjH18+fPx/e3t7KttFo1OQnJSWhcePGiI+Px9ChQxEQEIBvv/0WPXr0wIoVK/Dyyy8rZX/44Qd07twZDRo0UD543377LXr37o3r169j2LBhAB4EA8ePH0f79u1RtmxZuLi4YNeuXRg2bBj27NmDb775RjnmgQMH0LBhQ4SFhWHkyJHw9PTExo0bMXToUJw5cwazZs0CAFSqVMkm6ACA5cuXY/PmzWjTpo1N3oQJExAcHKzZV6hQIc32vn370KRJE/Tt2xceHh44dOgQpkyZgi1btmD79u1wcXkQEx48eBCNGzeGxWLBuHHjkJmZiXnz5qFZs2bYu3cvKlSooLmmmjVromfPnvDx8cHJkyexaNEirF+/Hn/88Qe8vLwAAHfu3EGDBg1w9+5dDBo0CBaLBYcPH8bcuXOxdetWHDhwQDk/ALz22mtYsWIFevfujcGDB+Pu3bs4dOgQrl69qpTp0qULypUrZ/NejB49Gnfu3EF4eLhNHgDMmTMHFy5csJt38eJFNGjQAEajESNGjICXlxeWLl2KNm3a4JdffkHTpk2VsocOHUJwcDAiIyNRuHBhnDt3DosWLcKPP/6Iw4cPIzAw0O45yFZe2/6dO3fQokULJCYmYvTo0TCZTIiKikKzZs3wxx9/wN/fXym7cOFCDBw4EF27dsU777yDHTt2YMiQIbh37x5GjhyplNu9ezdmz56NypUro1KlSnaDYCD37XTp0qXo168fnnvuOXzyyScwGo34888/cfHiRU25jRs3onPnzmjevDnmzJmDo0eP4uOPP8bVq1cxf/58pVxMTAxcXFwwcOBABAQE4ObNm/j666/RtGlTrF+/Hm3btlXKpqWloUOHDti1axfeeOMNVK9eHTdv3sSePXuQmJiIoKAgAMDUqVOxc+dOdO/eHdWrV8eVK1cwd+5c1K5dG7///juqVq2qHHPkyJGYNm0aunXrhqFDh+LEiROYM2cOjh8/jp9++kkpl5s2BeR/29+wYQMWL16M6tWrIyQkJNvAJjd/H2bOnGnzT9T58+cxZswYze+9adOmdj8jUVFROHz4MFq1apXrY2a9p40aNQIADBw4EKVKlUJcXBz27t1r99pyRQrYnj17BIB8+umnyr7k5GQJDQ2VBg0aOHztuHHjBIBcu3bNYblp06YJAPnll1+UfRkZGRIeHi4BAQGSkpKi7H/uueckMDBQ7t+/r+xLS0uT0NBQqV69eo7XM3jwYAEgly9fVva98cYb4ubmJgkJCZqyTZs2FV9f3xyPWa5cOQkLC9PsW7p0qQCQffv25fh6e6ZPny4AZPfu3cq+9u3bS+HCheX69evKvri4OPH29pYuXbrkeMw1a9YIAFm5cqWyb8WKFQJAfvzxR03ZDz/8UADIwYMHlX2rVq0SALJ27dpcX8+FCxfEYDDIG2+8YTc/Pj5e/Pz8ZMKECTafNxGRQYMGiaurq5w6dUrZd/fuXbFYLFK7du0cz79//34BIJMnT8513fXqYdr+1KlTBYDs3btX2Xfy5EkxGo0yatQoZd+9e/fE399fOnTooHn9K6+8Il5eXnLjxg1lX0JCgiQlJYmIyKeffioA5Ny5c05fj712eu7cOTGbzTJkyJAcX1+5cmWpUaOGpKWlKfs++OADMRgMcvLkSYevvXv3rpQoUUKef/55zf6pU6eKyWSSPXv2OHz9zp07NfdBEZGYmBhxd3eXV155RdkXFxcnrq6u8o9//ENTds6cOQJAfvjhB2VfbtrUo2j7V65ckXv37omIyFtvvSXZ/bnLzd8HeyZOnCgAZOfOnQ7L3bt3T3x8fOS5557L8ZqyO2a7du0kODhYc4/OLwU+TLBmzRoYjUb0799f2efh4YF+/fph9+7dNtGzPSKCpKQkSDZfwLhjxw4UK1YMLVu2VPa5uLigR48euHLlCrZt26bsT0pKQuHCheHu7q7sc3V1RdGiRWE2m3OsS9myZQEAt27d0hzTw8PD5j/2kiVL5njMvXv34vTp03jllVeyLXP79m3NcIMz7NVzx44daN26tea/qpIlS6JZs2b48ccf7Q4r5HTMpKQkAECJEiU0ZUuWLAkAmuufMWMGIiIi8OKLLyIzM9Nut2N2Vq5cCRHJ9n16//33UaFCBbz66qt283fs2IFatWppej88PT0RGRmJgwcP4q+//nJ4fnvXTo49TNtfs2YNwsPDNf8JVqxYEa1atcK3336r7Nu6dSsSEhIwaNAgzevfeust3L17F+vXr1f2FSlSBD4+Pnm6luza6YIFC5CRkYEJEyYAeNCjYe8+deLECZw4cQL9+/eHq+v/ddgOGjQIIoI1a9Y4PL+npyeKFSum+fxlZmZi1qxZePHFFxEREYH09HTcu3fP7usbNmwINzc3zb6wsDBUqVIFJ0+eVPbt3r0b6enp6Nmzp6Zs1vZ//vMfZV9u2tSjaPslSpRw6p6dm78P9nzzzTcIDg5Gw4YNHZZbt24dbt++7fBe7uiYp06dwsaNGzFixAj4+/vj/v37doek86rAg4FDhw6hfPny8PX11eyPiIgAgGy76tRCQkKUsbhXX30V8fHxmvyUlBS7HwpPT08AD7q8szRv3hzHjx/H2LFjcfr0aZw5cwYTJ07E/v378d5779kcIzU1FdevX8fFixcRHR2N6dOno0yZMpqurObNmyMpKQkDBgzAyZMncf78eSxYsABr167FqFGjHF5b1thSdh+gFi1awNfXV2lk2f3RSk9Px/Xr1xEXF4fNmzdjzJgx8PHxUd7nnN6n1NRUHDt2TLNfRHD9+nVcuXJF6Xo1Go1o3ry5UqZp06ZwcXHB0KFD8fvvv+PSpUvYsGEDJk2ahM6dO6NixYoAHgQNe/fuRXh4OEaPHq3MwwgJCdHc3B29TxaLxabrEXhwo162bBlmzpyZ7bhhbj4jWRISEnD16lXs378fffv2BQBN9x85lte2n5mZiSNHjqBu3bo2eREREThz5gxu376tnAOATdk6derAxcVFyX9Y2bXTLVu2oGLFitiwYQOCgoLg4+MDf39/jB07FpmZmUq57OoZGBiIoKAgu/VMSkrC9evXcerUKYwePRrHjh3TfP5OnDiBuLg4VK9eHf3794eXlxe8vLxQvXr1bMft1UQE8fHxKFq0qLIvJSUFAGzair124mybepRt3xl5aftZDh06hJMnT2qGEhzV02w2o0uXLg7LZXfMLVu2AHgQ5LRq1Qpmsxlmsxnt2rXLn/lK+d7XkEtVqlSRli1b2uw/fvy4AJAFCxZk+9qZM2fK4MGDZcWKFbJmzRoZOnSouLq6SlhYmCQmJirl/vWvf4mLi4vExsZqXt+zZ08BIIMHD1b23blzR3r06CEGg0EACADx9PSU77//3m4dVq5cqZQDIHXr1pUjR45oyqSnp8vgwYPFZDIp5YxGo8yfP9/he5Oeni4lSpSQiIgIm7xVq1ZJnz59ZNmyZRIdHS1jxowRT09PKVq0qFy4cMGm/O7duzX1rFChgmzdulVTplq1alK+fHlJT09X9qWkpEjp0qUFgKxZs0ZT/vLly5pjBgUFyapVq2zOvXjxYilUqJCm7D//+U9Nd+jBgwcFgPj7+0uJEiVk3rx5smLFComIiBCDwSAbN27M9n06duyYAJD33nvPJi8zM1MiIiKkV69eIvKg2xZ2hgk6duwohQoVUrqJszRo0EAAyPTp022O7e7urlyPv7+/zJ49O9s6kq28tv1r164JAJkwYYJN3ueffy4AlK7pt956S4xGo93jFCtWTHr27Gk3LzfDBI7aqa+vrxQuXFjc3d1l7NixsmbNGnn55ZcFgLz//vs257PXdsPDw6V+/fo2+59//nnl8+fm5iYDBgyQ5ORkJX/t2rXKZzMsLEyWLl0qS5culbCwMHFzc5PDhw87vK7ly5cLAFmyZImy78CBAwJAJk6cqCm7adMmASDe3t7KPmfb1KNq+2qOhgly8/fB2vDhwwWAnDhxwuH5ExISxM3NTXr06OGwnKNjDhkyRHmf2rZtK6tWrZJPP/1UvL29JTQ0VO7evZvjsR0p8GAgJCRE2rVrZ7P/zJkzAkCioqJydbysMWr12O3hw4fFZDJJRESE7Ny5U06fPi2ffPKJcjPv16+fUjYtLU3GjBkj3bt3l5UrV8rXX38tTZs2FW9vb834epYrV67Izz//LKtXr5aBAwdKgwYN7JaLioqSF154QZYtWyarVq2Szp07i6urq0RHR2d7LT/99JMAkFmzZjl17Tt27BCDwSADBgywyUtMTJSff/5Zvv/+e3nvvfekdu3asm7dOk2Z+fPnK3+ojx8/LkePHpWXXnpJCWKWL1+uKZ+SkiI///yzrFu3TiZMmCA1a9bU3DiybNy4Udq0aSMzZ86U6Ohoeeedd8TV1VWGDx+ulNm+fbtyY/v999+V/bdv35aiRYtKo0aNsr3uUaNGCQC7N7cvv/xSzGazcpPNLhjYsGGDAJB27drJwYMH5c8//5ShQ4cq12598xMR+fXXX2XDhg3y2WefSa1atThfIJfy2vYvXLggAGTq1Kk2eUuWLBEAcujQIRERee2118RsNts9jsVikU6dOtnNy00w4Kiduri4CACZMmWKZn/btm3FbDYrfyiz5rLEx8fbHKNJkyZSo0YNm/2HDh2SzZs3y5IlS6Rp06bSt29fuX37tpL/73//WwkU1EHG+fPnxWQyaeYCWDt58qT4+vpKgwYNNP8ciIjUq1dPvL295csvv5Rz587Jhg0bpEyZMmIymTSBl7Nt6lG1fTVHwUBu/j6oZWRkSKlSpaRWrVoOzy0isnDhQgEg//3vfx2Wc3TM1157TQBIlSpVJCMjQ9mf9Q/pokWLcqyHIwUeDDxMz0B2AgICpFWrVpp9q1evFn9/f+VDFxAQoPzxGzp0qFJuwIABUqNGDc2bnZqaKmFhYXYjf2uTJk0Sb29vzQTCyZMnS0BAgKahiog0b95cAgMDNf8hq/Xu3VuMRqNcuXLFmcsWEZH69etLaGhojuVWrFghLi4u8scff2j2jx49WtODUbduXfnggw8EgMPAReTBJCQAmiDjf//7nxiNRpuJjuPHjxeDwSDHjx8XEZF9+/YJAAkODrY5bt++fcVkMtl9nzIzM6VMmTJStWpVm7zExEQpUaKEfPjhh8q+7IIBkQeToLy8vJRrL1eunDK5KKeg9PTp0+Lh4SFz5sxxWI7+z7PSM+ConWZ9ns6fP6/Zv2zZMgEg27Zt05wvNz0DaikpKVKlShXp2rWrsm/16tUCQFq0aGFTvkWLFnbbmsiDHr+QkBCxWCzy999/2+RfunRJGjVqpOnlHDFihERERIifn5+mrDNt6lG0fWuOggER5/8+qP3666/Z9hpaa9q0qRQpUkRSU1MdlnN0zKxr+OijjzT709PTxdXVVfr27ZtjPRwp8DkDJUuWxOXLl232Z+3LyzIti8WCGzduaPZ169ZNWYKxe/dunD9/HiEhIQCA8uXLA3gw/r9kyRJ06NBBs9zNZDKhXbt22L9/P1JTUx2eu1u3brhz5w7++9//KvvmzZuHli1bapY/AkBkZCTi4uLsjvckJycjOjoarVu3tpl8l9trtydr3Eo94QcAJk2ahPj4eOzYsQNHjhzBvn37lLHNrPcpOw0bNkTJkiU1a2gXLlyIEiVK2IyFRkZGQkSwa9cuAP/3e7Z3rcWLF0daWprdSUU7d+7E+fPn7c6pmD59OlJTU/HSSy8hNjYWsbGxytrqmzdvIjY2VvP7HDx4MOLj47Fr1y7s378fp06dgp+fn1PXHhoailq1ammunRzLa9svUqQI3N3dnXptyZIlkZGRoVmeBjxo6wkJCQ+9DDSndprd57p48eIAHnwOs+qprr/a5cuXc6ynm5sbIiMjsXbtWiQnJzs8d9b5s86tlpiYiHbt2uHWrVvYtGmT3fOWKlUK//vf/xATE4Pt27fj0qVLmDZtGi5evGjTTpxpU4+i7eeWM38frK1YsQIuLi7o1auXw2NfuHABO3bsQPfu3WEymRyWdXTM7N4no9EIf39/u7/P3CjwYKBmzZqIiYlRZp1n2bNnj5KfGyKC2NhYFCtWzCbPzc0N4eHhqF+/Ptzc3JQJGa1btwbwYEJYenq63Zn5aWlpyMzMzHHWflZDTExMVPbFx8dne0wANg8VAR4878DZmadqZ8+etXvt1lJSUpCZmampZ5bChQujcePGqFatGoAHE1eCgoKUyX6O3L9/P0/XHhgYiICAAPz99982ZePi4uDh4WF3pveKFStgMBjsTuC5cOECbt68iSpVqiA4OBjBwcFo0qQJgAcPTQoODsaJEyc0r/Hy8kKDBg1Qp04dGI1GbNmyBWazWVnb60hycrLd95Psy2vbd3FxQbVq1bB//36bvD179iAkJET5rGQdw7rs/v37kZmZmev7i7Wc2mmdOnUAwOZzHRcXBwBKW82unnFxcbh06ZJT9UxOToaIKJMnq1WrBpPJlG2bsr5P3L9/Hx07dkRMTAx+/PFHVK5c2eH5wsLC0KRJEwQEBODEiRO4fPmyci9Vy6lNPYq2nxc5/X1QS0lJwXfffYfmzZvnGKjltNLJ2WNm91nKmsTuzH3foYfqV8gHv//+u0237f3796VcuXJSr149Zd/58+dt1tpevXrV5nhZ3YQzZsxweN6YmBjx8fGRF154QdmXnp4uhQoVkvLly2vWlt6+fVuCgoKkYsWKyr5r165JZmamzXGznjOgXrNatWpVKVKkiGZtaHp6utSpU0d8fHzsdh1FRkaKp6enzdCCo2tfv369ANCsab5586bd42c9Z8DeGL/af/7zH5tuqzt37tidrJL1nIGxY8cq+7LeD+vJim+//bbNGOHQoUMFgGzevFnZd+3aNfH19ZX27dvbnC81NVX8/f2lSZMmdut+4MABiY6O1vxkjd316dNHoqOj5datW9le+86dO8VoNGomEKWlpWnWpmfZs2ePGI1Gm/XXlL2HaftTpkwRQPucjVOnTonRaJSRI0cq++7duydFihTRtHMRkVdffVU8PT1tnv2RxdlhgpzaaXR0tACQ0aNHK/syMjKkcePGUqRIEc3zTCpWrCg1atTQjNGPGTNGDAaDZjKZvXkFN2/eFIvFIhaLRbO/U6dOYjQaNe/fiRMnxGg0yqBBg5R96enpEhkZKa6urrJ+/XqH12wtIyNDOnToIJ6enjbDIdbstSmR/G/71nIaJrBm7++DWtbkzJzunyIi1atXl9KlS9v9e5GbY96/f1+KFy8uISEhmomiWfe0b7/9Nse6OFLgwYCISPfu3cXV1VVGjBghCxculIYNG4qrq6syniYi0qxZM5tfptlslj59+shnn30mn3/+ufTq1UsMBoPUrFnT5o9VpUqV5MMPP5TFixfLBx98IEWKFJEyZcrIpUuXNOU+/vhjASC1atWSqKgomT59ulSqVEkAyNdff62Ui4qKkgoVKsjIkSNl4cKFMn36dHnuuecEgHTs2FFzzK+//loASGhoqEydOlVmz56tzKj9+OOPbd6PhIQEMZlM2Y5nijx4wEn37t1l6tSpsmDBAunfv7+4urqKxWLRjF1GR0eLxWKRYcOGybx582TmzJnStWtXMRgMUrduXU3Qs23bNmnVqpVMnTpVFi9eLK+//roYjUZp27atZszu0KFD4u/vL4MGDZLZs2fL3LlzpU+fPuLq6iply5bVBD2nTp0SLy8v8fb2llGjRsmCBQukV69eAsDm4RtXrlyRkiVLio+Pj4wbN05mzJgh5cuXF7PZbDO3QURk3bp1uZ5Xkt2cgdjYWImIiJCPP/5YFi9eLMOGDROz2Sy1atXSzIa+efOmeHl5yWuvvSafffaZLFiwQN566y3x9PSUIkWKSExMjNN1oby3/aSkJAkNDZXixYvLtGnTJCoqSiwWiwQGBtoEyln/IHTr1k0WLVokvXv3FgAyadIkTblbt27JxIkTZeLEidK2bVsBIMOHD5eJEyfanQviTDvNzMyUVq1aicFgkP79+8vnn3+u3CcWLlyoKbtu3ToxGAzSsmVL+eKLL2TIkCHi4uJi8zCd2rVrS2RkpEyaNEkWLVokY8eOlaCgIHFxcZHVq1dryh4/fly8vb2lZMmSMnnyZJk8ebKULFlSihUrprn3Zf0x7tixoyxfvtzmR23IkCHSv39/mTdvnsyaNUvq1asnBoNB/v3vf2vKOdumRB5N24+NjVV+n/Xq1VMmLU6cONGmrs7+fcjStWtXcXd3d/jPhIjI0aNHbVaOZMeZY2bNNQkPD5fZs2fLu+++KyaTSZo0aWIz0TO3nohgIDk5Wd59910JCAgQd3d3CQ8Pl02bNmnK2LshvP7661K5cmXx8fERk8kk5cqVk5EjR9p80EQeLBOxWCzi5uYmgYGBMnDgQLsRtogoy1oKFSokZrNZ6tWrZ7Osbt++fdK9e3cpXbq0uLu7i5eXl9SuXVtmzJhhd7LLpk2bpFmzZlK0aFFxc3OTatWqZftBXrBggQDap3lZ++CDD6RmzZri5+cnJpNJSpcuLW+++abNJKbTp09L7969JSQkRMxms3h4eEiVKlVk3LhxcufOHZuybdq0kaJFi4q7u7tUrFhRJk+ebPMErmvXrkn//v2lYsWK4uXlJW5ubhIWFiZvv/223adBnjp1Srp16yYWi0VMJpOUKVNG3n33Xbu9C2fOnJEXX3xRfH19xWw2S8uWLTVPmVPr2bOnmEymbP+7sye7YODGjRvSqVMnCQgIEDc3NwkODrb7WUpJSZGhQ4dK9erVxdfXV7mefv365eppdfRAXtu+iMjFixelW7du4uvrK97e3vLCCy/IX3/9Zfc8X3zxhVSoUEHc3NwkNDRUoqKibP5Ty/ps2PspU6aMzTGdaaciD3oWhw4dqny2qlWrpvnHQi06Olpq1qwp7u7uEhQUJGPGjLHp2Zs7d640btxYihYtKq6urlKsWDHp2LGjbN++3e4xDxw4IK1btxYvLy/x8fGRTp062QStWe9xdj9qS5culRo1aijHa9Wqlfz6668253W2TWXJ77a/devWbK+nWbNmNsdz9u9DYmKieHh4OPVU1vfff18A2Cw3f5hjrly5UmrUqCHu7u5SokQJGTx4cLbvaW4YRLJ5bB8RERHpQoFPICQiIqKCxWCAiIhI5xgMEBER6RyDASIiIp1jMEBERKRzDAaIiIh0ztWZQpmZmYiLi4OPj0+23wdPRI+O/P/HzAYGBmq+N+NJx3sHUcFy9t7hVDAQFxcHi8WSb5Ujory5ePEigoKCCroaTuO9g+jJkNO9w6lgIOtLIi5evAhfX9/8qRkROS0pKQkWi8XuF7Y8yXjvICpYzt47nAoGsrr3fH192aCJCtDT1tXOewfRkyGne8fTM/hIREREjwSDASIiIp1jMEBERKRzDAaIiIh0jsEAERGRzjEYICIi0jkGA0RERDrHYICIHjkRUX6I6MnDYICIiEjnGAwQERHpHIMBIiIinWMwQEREpHMMBoiIiHSOwQAREZHOMRggIiLSOQYDREREOsdggIiISOcYDBDRI8cnEBI92RgMEBER6RyDASIiIp1jMEBERKRzDAaIiIh0jsEAERGRzjEYICIi0jkGA0RERDrHYICIiEjnGAwQERHpHIMBIiIinWMwQEREpHMMBoiIiHSOwQAREZHOMRggIiLSOQYDREREOsdggIiISOcYDBAREekcgwEiIiKdYzBARESkcwwGiIiIdI7BABERkc4xGCAiItI5BgNEREQ6x2CAiIhI5xgMEBER6RyDASIiIp1jMEBERKRzDAaIiIh0jsEAERGRzjEYICIi0jkGA0RERDrHYICIiEjnGAwQERHpHIMBIiIinWMwQEREpHMMBoiIiHSOwQAREZHOMRggIiLSOdeCrgARERW8zMxMu2kAcHFxcbhNTz/+RomIiHSOwQAREZHOMRggIiLSOc4ZICLSIRHRbMfHxyvp7777TpMXGBio2W7SpImS9vLy0uR5eHgoac4teHrwN0VERKRzDAaIiIh0jsMEREQ6lJaWptn+17/+paR/+uknTZ6bm5tmu3379kraYrFo8ho2bKikn3/+eU2eyWTKW2XpkWPPABERkc4xGCAiItI5BgNEREQ6xzkDREQ6oX7M8G+//abJS0pKUtIpKSmavPv372u2169fr6Stlx1GR0cr6bt372ryevTooaQNBoOTtabHgT0DREREOsdggIiISOc4TPAMy6kbzvoJZET0bLt3756SjomJ0eQdPHhQSVsvO7SWmJiopGvXrq3Ji42NVdJRUVGavDZt2ijpwoUL51xhemzYM0BERKRzDAaIiIh0jsEAERGRznHOwDMmN8t11GU5f4Do2Xfu3Dkl/dFHH2nyEhISnD6Oeoni0aNHNXmvvPKKklYvMwSARYsWKel3331Xk8dvOCxYfPeJiIh0jsEAERGRznGY4CnHp3gRkbMyMjKU9PXr1/PlmNeuXdNsf/jhh0q6atWqmrx58+Yp6ZdfflmTFxQUlC/1obxhzwAREZHOMRggIiLSOQYDREREOsc5AwTAdu4BlxoSPf3UcwQAoGPHjvl+Dut7xZUrV5R0o0aNNHnDhw9X0mPHjtXkzZkzR0l7e3vnZxXJCewZICIi0jkGA0RERDrHYYKnEJcTEpEzrL998NKlS4/8nOqlhV999ZUmT939v2nTJk2eumz//v01eW5ubvlXQbKLPQNEREQ6x2CAiIhI5xgMEBER6RznDBARPaOOHDny2M+5efNmJe3p6anJU39rYffu3TV5s2bNUtJly5bV5LVv315J89sNHw2+q0RERDrHYICIiEjnOExAdqmXL/JphERPj+TkZCWt7l5/XBITE5X0nTt3NHmNGzdW0iaTSZOn/vbDKVOmaPIqVaqkpENDQ/OlnqTFngEiIiKdYzBARESkcwwGiIiIdI5zBp4CfPwwETkrNTVVSSckJBRgTYAGDRpoto8ePaqkR40apckbP368ko6JidHkffrpp0p6xowZmjzr5YuUN+wZICIi0jkGA0RERDrHYYKnnKNlf/k1vGB9HC41JHpyWLfHRo0aOfU66yf5qY+TX2382LFjmu379+8r6X79+mny1MME6uWRAPDTTz8p6bVr12ryevXqpaSNRmOe66p37BkgIiLSOQYDREREOsdggIiISOc4Z+AJxeWEROSMzMxMzfbx48edet2bb76p2e7atauSbtmy5cNXzI46deooaet69u7dW0kvW7ZMk6d+xHFUVJQmr169eko6LCwsX+qpR+wZICIi0jkGA0RERDpnECfWkCQlJcHPzw+JiYnw9fV9HPXSPWeHCXKzBOhRDD1wmeHj8bS2wax637x5U6m39ZI2ejhJSUmabT8/P6deZ/2tgWfPnlXSc+fO1eRNnTo1j7XL3r179zTbf/31l5JWd/0D2rq6u7tr8tTDG9b1dnXlSLiz9w62SiIiIp1jMEBERKRzDAaIiIh0jgMqTyGO0xPpm3o5YXh4uNOva9WqlZJeuHChJi8oKEhJT5kyRZP3KOYMrFu3TrMdGRmppK3nBaSlpdlNA8C2bduU9OXLlzV5FovloeupF+wZICIi0jkGA0RERDrHYICIiEjnOGfgCfE4Hj9sPdeAjzwmejqp1+jHxMQ4/boxY8Yo6dDQUKdfZ32O8uXLO/3a7AwZMkSz3aNHDyU9a9YsTd6AAQOUtPVzKhISEpT0pk2bNHmvv/66kub9zjH2DBAREekcgwEiIiKd4zABPRTrrjcueyRynqP2om5b1t9M2KhRozydr23btkra+jHGbm5u2b7uUXwbYHx8vGb7zp07SrpDhw6aPPV7kZGRoclLTU1V0qtXr9bkvfrqq0rabDbnvbI6wJ4BIiIinWMwQEREpHMMBoiIiHSOcwYKUF6XunCJDNGzQT1nwFG7Vo+LA8CRI0fydL6UlBQlbf3I34JWq1YtJa3+OmMAqF+/vpLevXu3Jk89h+DPP//U5B09elRJR0RE5Es9n1XsGSAiItI5BgNEREQ6x2ECylfqrk4uMyTSsm4T6m3rJ+up3bhx45HV6Ulx+vRpJW19vV988YWSrlGjhiZPvexSvTwRAJYvX66k1cMQAGAymfJe2WcQewaIiIh0jsEAERGRzjEYICIi0jnOGXhCPe7xdi5XJHr8HLVz9Vj4iy++6PQx1Y/ddXV1zTZv/Pjxmjz1I4CtH02sXqIHaB/ze/XqVafr5qw2bdpotvfv36+kFyxYoMl78803lbT1+6lehnj27FlNXoUKFR66ns8S9gwQERHpHIMBIiIinTOIE/3RSUlJ8PPzQ2JiInx9fR9HvZ5JuemKfxaHCbjUMO+e1jaYVe+bN28q9Xa0hO5Z5+y3FAJAWlqaknb0jYLWoqOjlXTnzp2dr1wePe57R3p6uiZP/Y2K1ksLjUajku7SpYsmb9q0aUra29s7X+r5JHL23qHfVklEREQAGAwQERHpHoMBIiIinePSQgJgO5bJpYZE+e/48eOa7fv37yvpunXravKsl8I56x//+IeSvn37dp6OkRtTpkzRbL///vv5fg71PAHr5ZLr1q1T0t26ddPkXblyRUmvX79ek2exWJT0iBEjNHnW59AD9gwQERHpHIMBIiIinePSwkfM2e72J23Z3aMYJnjSrvFp8rS2QT0uLczIyNBsq5cI/vOf/9Tk/fLLL0o6PDxck7dp0yanzufh4aHZVrdd66V2+fXeq9uy+voAwN3dPV/OoVa6dGklbT3U4unpqaSHDx+uyVuyZImStu76L1y4sN1yANC8efM81/VJw6WFRERE5BQGA0RERDrHYICIiEjn9Ld+4hHIj/F1R8d4VGPtj3v5YEFcI9GjoP5GwaSkJE3ehQsXNNuXLl1S0gcOHNDkJSQkKGln5whYUy9PtHbixAnNdtWqVfN0Duv2+bjnfajfUx8fH03exIkTlbT19arrbT2X4+bNm0p60qRJmryIiAjNtnpewrOKPQNEREQ6x2CAiIhI5zhM8BSw7l5nlzrR42X9JL9t27Yp6a+++kqTd+rUKc22ujtanX4cqlWrptlu27atkv7+++81eY6WBFovH3ySjBs3TklbDyGo753qoR1r1sMLu3bt0my3bt36Yar4VGDPABERkc4xGCAiItI5BgNEREQ6xzkD+eBpHcN/WutN9Dio5wl89tlnmrzvvvtOSauXBwK2S/3UY9XWbU69ZM1oNGryypQpo6Tnz5+vyatSpYqSvnr1qiZv9erVSvrYsWOavEOHDinp2NhYTV758uWVtPU8JTc3N822+lsEb9y4oclTf1Og+pG/ADSPw7V+jLJ6uaL1+dXn++233zR5L730kpK2Xj6oPqb1nAH1dnJysibvm2++0WyrH0/8rH6jIXsGiIiIdI7BABERkc49m/0dRES5pO6KBoDNmzcr6ejoaE2eumvcetmddRe3ejswMFCTp/4GPutuc2dZd8WPGTMm27KOvm0wN08kVQ9pFCtWTJNnvZ0f1Od7/vnnNXlnzpxR0tZLKa2/tVHN0dMJDx8+rNm+deuWki5atGjOFX4KsWeAiIhI5xgMEBER6RyDASIiIp3jnAEi0i318rJr165p8tavX6+krb+ZUD3ebL3szpp6bD4kJESTp17Sltc5A3llvUROfU2P+xtNH4b6PTSbzZo89fJQ62Wdjq7Rernk6dOnlTTnDBAREdEzicEAERGRznGYgIh0w7qrODU1VUlfv35dk2cymZS0+sl5gHYpmvXSPuuhAPV2q1atNHne3t7OVDvfOOoaf1qGBqx/h5cuXVLS6t8noL2m3Fy79TnOnj2rpMPDwzV51k+OfFqxZ4CIiEjnGAwQERHpHIMBIiIineOcASJ6pqnHfx19c52fn58mr0uXLkq6bt26mryAgAAlXblyZU1e8eLFNdvqJYPWy/kKcpz+aZkjYM360cHqb0lUf0sh4HjOgLqs9e/FeplnSkqKkrb+DHHOABERET0TGAwQERHpHIcJiEg3rLuK3d3dlXTJkiU1eeqhAOvXqbuGrbum6dGy/l1UqlRJSYeFhWnyjhw5oqSthxfUv0PrJxdaH0c9FPS0Dq/khJ9iIiIinWMwQEREpHMMBoiIiHSOcwaI6Jnm7CNpn5UlYs86699TaGiokv7iiy80eUuXLlXS+/fv1+SpHzdt/Yjh9u3ba7bVcwae1c8JewaIiIh0jsEAERGRzjEYICIi0jnOGSAioqeW+lHC1l8f/dFHHynp9PR0TZ76MdXW8wCsnx2hh2dJPPtXSERERA4xGCAiItI5DhMQEdEzSd297+bmVoA1efKxZ4CIiEjnGAwQERHpHIMBIiIinWMwQEREpHMMBoiIiHSOwQAREZHOMRggIiLSOQYDREREOsdggIiISOcYDBAREekcgwEiIiKdYzBARESkcwwGiIiIdI7BABERkc4xGCAiItI5BgNEREQ6x2CAiIhI5xgMEBER6RyDASIiIp1jMEBERKRzDAaIiIh0jsEAERGRzjEYICIi0jkGA0RERDrnWtAVIKJnn8FggMFgKOhqEFE22DNARESkcwwGiIiIdI7BABERkc4xGCAiItI5BgNEREQ6x2CAiIhI57i0kIgeOS4tJHqysWeAiIhI5xgMEBER6RyDASIiIp1jMEBERKRzDAaIiIh0jsEAERGRzjEYICIi0jkGA0RERDrHYICIiEjnGAwQERHpHIMBIiIinWMwQEREpHNOfVGRiAAAkpKSHmlliMi+rLaX1RafFrx3EBUsZ+8dTgUDt2/fBgBYLJaHrBYRPYzbt2/Dz8+voKvhNN47iJ4MOd07DOLEvxqZmZmIi4uDj48Pv4aUqACICG7fvo3AwEC4uDw9o3u8dxAVLGfvHU4FA0RERPTsenr+xSAiIqJHgsEAERGRzjEYICIi0jkGA0RERDrHYICIiEjnGAwQERHpHIMBIiIinft/Vw/y+o3UHV4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chr_lambda = lambda a: chr(a + 65)\n",
    "dirname_grad = \"../unet_attack_result\" + \"/grad/\"\n",
    "dirname_org = \"../unet_attack_result\" + \"/org/\"\n",
    "dirname_adv = \"../unet_attack_result\" + \"/adv/\"\n",
    "dirname_res = \"../unet_attack_result\" + \"/resistance/\"\n",
    "dirname_pro = \"../unet_attack_result\" + \"/progress/\"\n",
    "for c in [chr(i) for i in range(65, 65+26)]:\n",
    "    os.makedirs(dirname_grad + c, exist_ok=True)\n",
    "    os.makedirs(dirname_org + c, exist_ok=True)\n",
    "    os.makedirs(dirname_adv + c, exist_ok=True)\n",
    "    os.makedirs(dirname_res + c, exist_ok=True)\n",
    "    os.makedirs(dirname_pro + c, exist_ok=True)\n",
    "    for d in [chr(i) for i in range(65, 65+26)]:\n",
    "        os.makedirs(dirname_adv + c + \"/\" + c + \"→\" + d, exist_ok=True)\n",
    "\n",
    "# 精度カウンター\n",
    "success = 0\n",
    "# count = 0\n",
    "count_list = [0] * 26\n",
    "loss_list = []\n",
    "defensibility_list = []\n",
    "\n",
    "# テスト用データセット内の全てのサンプルをループします\n",
    "for i, (data, target) in enumerate(test_loader):\n",
    "\n",
    "    # データとラベルをデバイス（CPUもしくはGPU）に送信します\n",
    "    data = (data >= 0.0) * 2.0 - 1.0\n",
    "    data, target = Variable(data).to(device), Variable(target.to(device))\n",
    "    generated = unet(data).detach()\n",
    "    generated = Variable(generated).to(device)\n",
    "    # data = generated.unsqueeze(0).to(device)\n",
    "    # テンソルの requires_grad 属性を設定します。攻撃者にとっては重要な設定です。\n",
    "\n",
    "    data.requires_grad = True\n",
    "    generated.requires_grad = True\n",
    "    # データをモデルに順伝播させます\n",
    "    output1 = model1(data)\n",
    "    output2 = model2(generated)\n",
    "    init_pred = output1.max(1, keepdim=True)[1] # 最大の確率のインデックスを取得します。\n",
    "\n",
    "    # 最初から予測が間違っている場合、攻撃する必要がないため次のイテレーションに進みます。\n",
    "    \n",
    "    if init_pred.item() != target.item():\n",
    "        continue\n",
    "\n",
    "    data_copy = data.detach().clone()\n",
    "    # character_coordinate = character_search(data_copy.data[0][0])\n",
    "\n",
    "    count_list[init_pred.item()] += 1\n",
    "\n",
    "    # 損失を計算します\n",
    "    loss1 = F.nll_loss(output1, target)\n",
    "    loss2 = F.nll_loss(output2, target)\n",
    "    # 既存の勾配を全てゼロにします\n",
    "    model1.zero_grad()\n",
    "    model2.zero_grad()\n",
    "    # 逆伝播させてモデルの勾配を計算します\n",
    "    loss1.backward()\n",
    "    loss2.backward()\n",
    "    # データの勾配を取得します\n",
    "    data_grad = data.grad.data\n",
    "    generated_grad = generated.grad.data\n",
    "    \n",
    "    # # 勾配のヒートマップ\n",
    "    # grad_map = data_grad.squeeze().detach().cpu().numpy()\n",
    "    # grad_map_abs = np.abs(grad_map)\n",
    "    # plt.xticks([], [])\n",
    "    # plt.yticks([], [])\n",
    "    # plt.imsave(dirname_grad + chr_lambda(init_pred.item()) + \"/{}.png\".format(count_list[init_pred.item()]), grad_map_abs, cmap=\"Reds\")\n",
    "\n",
    "    perturbed_data1, pred1, success1, count1 = attack(data, data_grad, target, model1,  dirname_res, dirname_pro, chr_lambda(init_pred.item()), count_list[init_pred.item()], 0.002, 0, success)\n",
    "    perturbed_data2, pred2, success2, count2 = attack(generated, generated_grad, target, model2,  dirname_res, dirname_pro, chr_lambda(init_pred.item()), count_list[init_pred.item()], 0.002, 0, success)\n",
    "    # loss_list.append(loss1.item())\n",
    "    # defensibility_list.append(count1)\n",
    "    if count1 <= 100:\n",
    "        data = data.squeeze().detach().cpu().numpy()\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])  \n",
    "        plt.title(\"{}\".format(loss1.item()))\n",
    "        plt.imshow(data, cmap=\"gray\")\n",
    "        generated= generated.squeeze().detach().cpu().numpy()\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        plt.title(\"{}\".format(loss2.item()))\n",
    "        plt.imshow(generated, cmap=\"gray\")\n",
    "        plt.savefig(\"../sample+loss_under100/\" + \"{}.png\".format(i + 1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
