{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import Generator,Discriminator,init_weights\n",
    "from utils import ImagePool,BasicDataset\n",
    "import argparse\n",
    "import time \n",
    "import os\n",
    "import sys\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np \n",
    "from memory_profiler import profile\n",
    "import pdb \n",
    "from torchvision.datasets import ImageFolder\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_fix_seed(seed=42):\n",
    "    # Python random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms = True\n",
    "torch_fix_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = \"../model/googlefonts.pth\" #事前学習済みMNISTモデル(重みパラメータ)\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=57600, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=26, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=57600, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(57600, 128)\n",
    "        self.fc2 = nn.Linear(128, 26)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "# 使うデバイス（CPUかGPUか）の定義\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "# ネットワークの初期化\n",
    "model = Net().to(device)\n",
    "print(model)\n",
    "# 訓練済みモデルのロード\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "\n",
    "\n",
    "# モデルを評価モードに設定。本チュートリアルの例では、これはドロップアウト層等を評価モードにするのに必要\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack(data, data_grad, target, dirname_res, dirname_pro, chr, count, epsilon, lim, success):\n",
    "    os.makedirs(dirname_pro + chr + \"/{}\".format(count), exist_ok=True)\n",
    "    # os.makedirs(dirname_pro + chr + \"/{}\".format(i), exist_ok=True)\n",
    "    for i in range(1, 10001):\n",
    "        data.requires_grad = False\n",
    "        sign_data_grad = data_grad.sign()\n",
    "        perturbed_data = data + epsilon * sign_data_grad\n",
    "        # perturbed_data += (perturbed_data < torch.Tensor([1 - lim]).to(\"cuda\")) * epsilon + (perturbed_data < torch.Tensor([0]).to(\"cuda\")) * -epsilon + (perturbed_data > torch.Tensor([-1 + lim]).to(\"cuda\")) * -epsilon + (perturbed_data > torch.Tensor([0]).to(\"cuda\")) * epsilon\n",
    "        perturbed_data = torch.clamp(perturbed_data, -1, 1)\n",
    "        data = perturbed_data\n",
    "        data.requires_grad = True\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        plt.imsave(dirname_pro + chr + \"/{}\".format(count) + \"/\" + \"{}.png\".format(i), data.squeeze().detach().cpu().numpy(), cmap=\"gray\")\n",
    "        if pred.item() != target.item():\n",
    "            success += 1\n",
    "            break\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        data_grad = data.grad.data\n",
    "    os.makedirs(dirname_res + chr + \"/{}\".format(i), exist_ok=True)\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.imsave(dirname_res + chr + \"/{}\".format(i) + \"/\" + \"{}.png\".format(count), data.squeeze().detach().cpu().numpy(), cmap=\"gray\")\n",
    "    return data, pred, success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class loss_scheduler():\n",
    "    def __init__(self, args):\n",
    "        self.epoch_decay = args.epoch_decay\n",
    "\n",
    "    def f(self, epoch):\n",
    "        #ベースの学習率に対する倍率を返す(pytorch仕様)\n",
    "        if epoch<=self.epoch_decay:\n",
    "            return 1\n",
    "        else:\n",
    "            scaling = 1 - (epoch-self.epoch_decay)/float(self.epoch_decay)\n",
    "            return scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_requires_grad(models, requires=False):\n",
    "    if not isinstance(models,list):\n",
    "        models = [models]\n",
    "    for model in models:\n",
    "        if model is not None:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = requires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--image_size IMAGE_SIZE]\n",
      "                             [--batch_size BATCH_SIZE] [--epoch EPOCH]\n",
      "                             [--epoch_decay EPOCH_DECAY] [--beta1 BETA1]\n",
      "                             [--lr LR] [--pool_size POOL_SIZE]\n",
      "                             [--lambda_cycle LAMBDA_CYCLE]\n",
      "                             [--lambda_identity LAMBDA_IDENTITY] [--gpu GPU]\n",
      "                             [--sample_frequecy SAMPLE_FREQUECY]\n",
      "                             [--checkpoint_frequecy CHECKPOINT_FREQUECY]\n",
      "                             [--data_name DATA_NAME] [--out OUT]\n",
      "                             [--log_dir LOG_DIR] [--model MODEL]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9018 --control=9016 --hb=9015 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"233da721-9a75-4af3-bfc9-a283424a0767\" --shell=9017 --transport=\"tcp\" --iopub=9019 --f=/home/hoge/.local/share/jupyter/runtime/kernel-v2-17585KlE7O8azs0Os.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch implementation: CycleGAN')\n",
    "    #for train\n",
    "    parser.add_argument('--image_size', '-i', type=int, default=64, help='input image size')\n",
    "    parser.add_argument('--batch_size', '-b', type=int, default=1,\n",
    "                        help='Number of images in each mini-batch')\n",
    "    parser.add_argument('--epoch', '-e', type=int, default=200,\n",
    "                        help='Number of epochs')\n",
    "    parser.add_argument('--epoch_decay', '-ed', type=int, default=100,\n",
    "                        help='Number of epochs to start decaying learning rate to zero')                    \n",
    "    parser.add_argument('--beta1', type=float, default=0.5, help='momentum term of adam')\n",
    "    parser.add_argument('--lr', type=float, default=0.0002, help='learning rate')\n",
    "    parser.add_argument('--pool_size', type=int, default=50, help='for discriminator: the size of image buffer that stores previously generated images')\n",
    "    parser.add_argument('--lambda_cycle', type=float, default=10.0, help='Assumptive weight of cycle consistency loss')\n",
    "    parser.add_argument('--lambda_identity', type=float, default=0, help='Assumptive weight of identity mapping loss')\n",
    "    parser.add_argument('--gpu', '-g', type=int, default=0,\n",
    "                        help='GPU ID (negative value indicates CPU)')\n",
    "    #for save and load\n",
    "    parser.add_argument('--sample_frequecy', '-sf', type=int, default=5000,\n",
    "                        help='Frequency of taking a sample')\n",
    "    parser.add_argument('--checkpoint_frequecy', '-cf', type=int, default=10,\n",
    "                        help='Frequency of taking a checkpoint')\n",
    "    parser.add_argument('--data_name', '-d', default=\"horse2zebra\", help='Dataset name')\n",
    "    parser.add_argument('--out', '-o', default='result/',\n",
    "                        help='Directory to output the result')\n",
    "    parser.add_argument('--log_dir', '-l', default='logs/',\n",
    "                        help='Directory to output the log')\n",
    "    parser.add_argument('--model', '-m', help='Model name')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "    #set GPU or CPU\n",
    "    if args.gpu >= 0 and torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "\n",
    "    #set depth of resnet\n",
    "    if args.image_size == 64:\n",
    "        res_block=3\n",
    "    else:\n",
    "        res_block=9\n",
    "    \n",
    "    #set models\n",
    "    G_A2B = Generator(1,res_block).to(device)\n",
    "    G_B2A = Generator(1,res_block).to(device)\n",
    "    D_A = Discriminator(1).to(device)\n",
    "    D_B = Discriminator(1).to(device)\n",
    "\n",
    "    # data pararell\n",
    "    # if device == 'cuda':\n",
    "    #     G_A2B = torch.nn.DataParallel(G_A2B)\n",
    "    #     G_B2A = torch.nn.DataParallel(G_B2A)\n",
    "    #     D_A = torch.nn.DataParallel(D_A)\n",
    "    #     D_B = torch.nn.DataParallel(D_B)\n",
    "    #     torch.backends.cudnn.benchmark=True\n",
    "\n",
    "\n",
    "    #init weights\n",
    "    G_A2B.apply(init_weights)\n",
    "    G_B2A.apply(init_weights)\n",
    "    D_A.apply(init_weights)\n",
    "    D_B.apply(init_weights)\n",
    "\n",
    "    #set loss functions\n",
    "    adv_loss = nn.MSELoss()\n",
    "    cycle_loss = nn.L1Loss()\n",
    "    identity_loss = nn.L1Loss()\n",
    "\n",
    "    #set optimizers\n",
    "    optimizer_G = torch.optim.Adam(chain(G_A2B.parameters(),G_B2A.parameters()),lr=args.lr,betas=(args.beta1,0.999))\n",
    "    optimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=args.lr, betas=(args.beta1,0.999))\n",
    "    optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=args.lr, betas=(args.beta1,0.999))\n",
    "    \n",
    "    scheduler_G = LambdaLR(optimizer_G,lr_lambda=loss_scheduler(args).f)\n",
    "    scheduler_D_A = LambdaLR(optimizer_D_A,lr_lambda=loss_scheduler(args).f)\n",
    "    scheduler_D_B = LambdaLR(optimizer_D_B,lr_lambda=loss_scheduler(args).f)\n",
    "\n",
    "    #dataset loading\n",
    "    class ImageTransform():\n",
    "        def __init__(self, mean, std):\n",
    "            self.data_transform = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((64, 64)),\n",
    "            transforms.Normalize(mean, std)\n",
    "            ])\n",
    "\n",
    "        def __call__(self, img):\n",
    "            return self.data_transform(img)\n",
    "    mean = (0.5,)\n",
    "    std = (0.5,)\n",
    "    weak_images = ImageFolder( \"../data/GAN_train_weak\", transform = ImageTransform(mean, std))\n",
    "    strong_images = ImageFolder( \"../data/GAN_strong\", transform = ImageTransform(mean, std))\n",
    "    train_weak_loader = torch.utils.data.DataLoader(weak_images, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "    train_strong_loader = torch.utils.data.DataLoader(strong_images, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    #######################################################################################\n",
    "\n",
    "    #train\n",
    "    total_epoch = args.epoch\n",
    "\n",
    "    fake_A_buffer = ImagePool()\n",
    "    fake_B_buffer = ImagePool()\n",
    "\n",
    "    for epoch in range(total_epoch):\n",
    "        start = time.time()\n",
    "        losses = [0 for i in range(6)]\n",
    "        for i, ((real_A, label_A), (real_B, label_B)) in enumerate(zip(train_weak_loader, train_strong_loader)):\n",
    "            #generate image\n",
    "            label_A = label_A.type(torch.LongTensor).to(device)\n",
    "            label_B = label_B.type(torch.LongTensor).to(device)\n",
    "            real_A = real_A.to(device)\n",
    "            real_B = real_B.to(device)\n",
    "            fake_A, fake_B = G_B2A(real_B), G_A2B(real_A)\n",
    "            rec_A, rec_B = G_B2A(fake_B), G_A2B(fake_A)\n",
    "            if args.lambda_identity>0:\n",
    "                iden_A, iden_B = G_B2A(real_A), G_A2B(real_B)\n",
    "\n",
    "            #train generator\n",
    "            set_requires_grad([D_A,D_B],False)\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            pred_fake_A = D_A(fake_A)\n",
    "            loss_G_B2A = adv_loss(pred_fake_A, torch.tensor(1.0).expand_as(pred_fake_A).to(device))\n",
    "            \n",
    "            pred_fake_B = D_B(fake_B)\n",
    "            loss_G_A2B = adv_loss(pred_fake_B, torch.tensor(1.0).expand_as(pred_fake_B).to(device))\n",
    "\n",
    "            loss_cycle_A = cycle_loss(rec_A, real_A)\n",
    "            loss_cycle_B = cycle_loss(rec_B, real_B)\n",
    "\n",
    "            if args.lambda_identity>0:\n",
    "                loss_identity_A = identity_loss(iden_A,real_A)\n",
    "                loss_identity_B = identity_loss(iden_B,real_B)\n",
    "                loss_G = loss_G_A2B + loss_G_B2A + loss_cycle_A*args.lambda_cycle + loss_cycle_B*args.lambda_cycle + loss_identity_A*args.lambda_cycle*args.lambda_identity + loss_identity_B*args.lambda_cycle*args.lambda_identity\n",
    "\n",
    "            else:\n",
    "                loss_G = loss_G_A2B + loss_G_B2A + loss_cycle_A*args.lambda_cycle + loss_cycle_B*args.lambda_cycle\n",
    "\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            losses[0]+=loss_G_A2B.item()\n",
    "            losses[1]+=loss_G_B2A.item()\n",
    "            losses[2]+=loss_cycle_A.item()\n",
    "            losses[3]+=loss_cycle_B.item()\n",
    "\n",
    "\n",
    "            #train discriminator\n",
    "            set_requires_grad([D_A,D_B],True)\n",
    "            optimizer_D_A.zero_grad()\n",
    "            pred_real_A = D_A(real_A)\n",
    "            fake_A_ = fake_A_buffer.get_images(fake_A)\n",
    "            pred_fake_A = D_A(fake_A_.detach())\n",
    "            loss_D_A_real = adv_loss(pred_real_A, torch.tensor(1.0).expand_as(pred_real_A).to(device))\n",
    "            loss_D_A_fake = adv_loss(pred_fake_A, torch.tensor(0.0).expand_as(pred_fake_A).to(device))\n",
    "            loss_D_A = (loss_D_A_fake + loss_D_A_real)*0.5\n",
    "            loss_D_A.backward()\n",
    "            optimizer_D_A.step()\n",
    "\n",
    "            optimizer_D_B.zero_grad()\n",
    "            pred_real_B = D_B(real_B)\n",
    "            fake_B_ = fake_B_buffer.get_images(fake_B)\n",
    "            pred_fake_B = D_B(fake_B_.detach())\n",
    "            loss_D_B_real = adv_loss(pred_real_B, torch.tensor(1.0).expand_as(pred_real_B).to(device))\n",
    "            loss_D_B_fake = adv_loss(pred_fake_B, torch.tensor(0.0).expand_as(pred_fake_B).to(device))\n",
    "            loss_D_B = (loss_D_B_fake + loss_D_B_real)*0.5\n",
    "            loss_D_B.backward()\n",
    "            optimizer_D_B.step()\n",
    "\n",
    "            losses[4]+=loss_D_A.item() \n",
    "            losses[5]+=loss_D_B.item()\n",
    "\n",
    "            #get sample\n",
    "            if i % 10 == 0:\n",
    "                chr_lambda = lambda a: chr(a + 65)\n",
    "                dirname_grad = \"../GAN_result\" + \"/grad/\"\n",
    "                dirname_org = \"../GAN_result\" + \"/org/\"\n",
    "                dirname_adv = \"../GAN_result\" + \"/adv/\"\n",
    "                dirname_res = \"../GAN_result\" + \"/resistance/\"\n",
    "                dirname_pro = \"../GAN_result\" + \"/progress/\"\n",
    "                for c in [chr(i) for i in range(65, 65+26)]:\n",
    "                    os.makedirs(dirname_grad + c, exist_ok=True)\n",
    "                    os.makedirs(dirname_org + c, exist_ok=True)\n",
    "                    os.makedirs(dirname_adv + c, exist_ok=True)\n",
    "                    os.makedirs(dirname_res + c, exist_ok=True)\n",
    "                    os.makedirs(dirname_pro + c, exist_ok=True)\n",
    "                    for d in [chr(i) for i in range(65, 65+26)]:\n",
    "                        os.makedirs(dirname_adv + c + \"/\" + c + \"→\" + d, exist_ok=True)\n",
    "\n",
    "                # 精度カウンター\n",
    "                correct = 0\n",
    "                success = 0\n",
    "                count_list = [0] * 26\n",
    "\n",
    "                # データをモデルに順伝播させます\n",
    "                output = model(fake_B)\n",
    "                init_pred = output.max(1, keepdim=True)[1] # 最大の確率のインデックスを取得します。\n",
    "\n",
    "                # 最初から予測が間違っている場合、攻撃する必要がないため次のイテレーションに進みます。\n",
    "                \n",
    "                if init_pred.item() != label_A.item():\n",
    "                    continue\n",
    "\n",
    "                correct += 1\n",
    "\n",
    "                data_copy = fake_B.detach().clone()\n",
    "            \n",
    "                # 損失を計算します\n",
    "                loss = F.nll_loss(output, label_A)\n",
    "                # 既存の勾配を全てゼロにします\n",
    "                model.zero_grad()\n",
    "                # 逆伝播させてモデルの勾配を計算します\n",
    "                loss.backward()\n",
    "                # データの勾配を取得します\n",
    "                data_grad = fake_B.grad.data\n",
    "\n",
    "                perturbed_data, pred, success = attack(fake_B, data_grad, label_A, dirname_res, dirname_pro, chr_lambda(init_pred.item()), count_list[init_pred.item()], 0.001, 0, success)\n",
    "\n",
    "                final_pred = pred\n",
    "\n",
    "                org = data_copy.squeeze().detach().cpu().numpy()\n",
    "                adv = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "\n",
    "                #各条件を満たす画像の保存\n",
    "                plt.xticks([], [])\n",
    "                plt.yticks([], [])\n",
    "                plt.imsave(dirname_org + chr_lambda(init_pred.item()) + \"/{}.png\".format(count_list[init_pred.item()]), org, cmap=\"gray\")\n",
    "                \n",
    "                os.makedirs(dirname_adv + chr_lambda(init_pred.item()) + \"/\" + chr_lambda(init_pred.item()) + \"→\" + chr_lambda(final_pred.item()) + \"/\", exist_ok=True)\n",
    "                plt.xticks([], [])\n",
    "                plt.yticks([], [])\n",
    "                plt.imsave(dirname_adv + chr_lambda(init_pred.item()) + \"/\" + chr_lambda(init_pred.item()) + \"→\" + chr_lambda(final_pred.item()) + \"/{}.png\".format(count_list[init_pred.item()]), adv, cmap=\"gray\")\n",
    "\n",
    "                images_sample = torch.cat((fake_B.data, fake_B.data, rec_A.data, fake_B.data, fake_A.data, rec_B.data),0)\n",
    "                os.makedirs(\"../sample/\" + str(epoch + 1), exist_ok=True)\n",
    "                save_image(images_sample, \"../sample/\" + str(epoch + 1) + \"/\" + str(i) + \".png\", nrow=3, normalize=True)\n",
    "                \n",
    "    \n",
    "            current_batch = epoch * len(train_weak_loader) + i\n",
    "            sys.stdout.write(f\"\\r[Epoch {epoch+1}/200] [Index {i}/{len(train_weak_loader)}] [D_A loss: {loss_D_A.item():.4f}] [D_B loss: {loss_D_B.item():.4f}] [G loss: adv: {loss_G.item():.4f}] [lr: {scheduler_G.get_lr()}]\")\n",
    "            \n",
    "        \n",
    "        \n",
    "        #get tensorboard logs\n",
    "        os.makedirs(args.log_dir, exist_ok=True)\n",
    "        writer = SummaryWriter(args.log_dir)\n",
    "        writer.add_scalar('loss_G_A2B', losses[0]/float(len(train_weak_loader)), epoch)\n",
    "        writer.add_scalar('loss_D_A', losses[4]/float(len(train_weak_loader)), epoch)\n",
    "        writer.add_scalar('loss_G_B2A', losses[1]/float(len(train_weak_loader)), epoch)\n",
    "        writer.add_scalar('loss_D_B', losses[5]/float(len(train_weak_loader)), epoch)\n",
    "        writer.add_scalar('loss_cycle_A', losses[2]/float(len(train_weak_loader)), epoch)\n",
    "        writer.add_scalar('loss_cycle_B', losses[3]/float(len(train_weak_loader)), epoch)\n",
    "        writer.add_scalar('learning_rate_G', np.array(scheduler_G.get_lr()), epoch)\n",
    "        writer.add_scalar('learning_rate_D_A', np.array(scheduler_D_A.get_lr()), epoch)\n",
    "        writer.add_scalar('learning_rate_D_B', np.array(scheduler_D_B.get_lr()), epoch)\n",
    "        sys.stdout.write(f\"[Epoch {epoch+1}/200] [D_A loss: {losses[4]/float(len(train_weak_loader)):.4f}] [D_B loss: {losses[5]/float(len(train_weak_loader)):.4f}] [G adv loss: adv: {losses[0]/float(len(train_weak_loader))+losses[1]/float(len(train_weak_loader)):.4f}]\")\n",
    "        \n",
    "        #update learning rate\n",
    "        scheduler_G.step()\n",
    "        scheduler_D_A.step()\n",
    "        scheduler_D_B.step()\n",
    "        \n",
    "        \n",
    "        os.makedirs(\"../models/G_A2B/\", exist_ok=True)\n",
    "        os.makedirs(\"../models/G_B2A/\", exist_ok=True)\n",
    "        os.makedirs(\"../models/D_A/\", exist_ok=True)\n",
    "        os.makedirs(\"../models/D_B/\", exist_ok=True)\n",
    "        torch.save(G_A2B.state_dict(), \"../models/G_A2B/\"+str(epoch)+\".pth\")\n",
    "        torch.save(G_B2A.state_dict(), \"../models/G_B2A/\"+str(epoch)+\".pth\")\n",
    "        torch.save(D_A.state_dict(), \"../models/D_A/\"+str(epoch)+\".pth\")\n",
    "        torch.save(D_B.state_dict(), \"../models/D_B/\"+str(epoch)+\".pth\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
