{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoge/.local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import heapq\n",
    "import itertools\n",
    "import copy\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_fix_seed(seed=42):\n",
    "    # Python random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms = True\n",
    "torch_fix_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = \"../model/googlefonts.pth\" #事前学習済みMNISTモデル(重みパラメータ)\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=57600, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=26, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=57600, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(57600, 128)\n",
    "        self.fc2 = nn.Linear(128, 26)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "# 使うデバイス（CPUかGPUか）の定義\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "# ネットワークの初期化\n",
    "model = Net().to(device)\n",
    "print(model)\n",
    "# 訓練済みモデルのロード\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "\n",
    "\n",
    "# モデルを評価モードに設定。本チュートリアルの例では、これはドロップアウト層等を評価モードにするのに必要\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack(data, data_grad, target, dirname_res, dirname_pro, chr, count, epsilon, lim, success):\n",
    "    os.makedirs(dirname_pro + chr + \"/{}\".format(count), exist_ok=True)\n",
    "    # os.makedirs(dirname_pro + chr + \"/{}\".format(i), exist_ok=True)\n",
    "    for i in range(1, 10001):\n",
    "        data.requires_grad = False\n",
    "        sign_data_grad = data_grad.sign()\n",
    "        perturbed_data = data + epsilon * sign_data_grad\n",
    "        # perturbed_data += (perturbed_data < torch.Tensor([1 - lim]).to(\"cuda\")) * epsilon + (perturbed_data < torch.Tensor([0]).to(\"cuda\")) * -epsilon + (perturbed_data > torch.Tensor([-1 + lim]).to(\"cuda\")) * -epsilon + (perturbed_data > torch.Tensor([0]).to(\"cuda\")) * epsilon\n",
    "        perturbed_data = torch.clamp(perturbed_data, -1, 1)\n",
    "        data = perturbed_data\n",
    "        data.requires_grad = True\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        plt.imsave(dirname_pro + chr + \"/{}\".format(count) + \"/\" + \"{}.png\".format(i), data.squeeze().detach().cpu().numpy(), cmap=\"gray\")\n",
    "        if pred.item() != target.item():\n",
    "            success += 1\n",
    "            break\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        data_grad = data.grad.data\n",
    "    os.makedirs(dirname_res + chr + \"/{}\".format(i), exist_ok=True)\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.imsave(dirname_res + chr + \"/{}\".format(i) + \"/\" + \"{}.png\".format(count), data.squeeze().detach().cpu().numpy(), cmap=\"gray\")\n",
    "    return data, pred, success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device):\n",
    "    chr_lambda = lambda a: chr(a + 65)\n",
    "    dirname_grad = \"../attack_result\" + \"/grad/\"\n",
    "    dirname_org = \"../attack_result\" + \"/org/\"\n",
    "    dirname_adv = \"../attack_result\" + \"/adv/\"\n",
    "    dirname_res = \"../attack_result\" + \"/resistance/\"\n",
    "    dirname_pro = \"../attack_result\" + \"/progress/\"\n",
    "    for c in [chr(i) for i in range(65, 65+26)]:\n",
    "        os.makedirs(dirname_grad + c, exist_ok=True)\n",
    "        os.makedirs(dirname_org + c, exist_ok=True)\n",
    "        os.makedirs(dirname_adv + c, exist_ok=True)\n",
    "        os.makedirs(dirname_res + c, exist_ok=True)\n",
    "        os.makedirs(dirname_pro + c, exist_ok=True)\n",
    "        for d in [chr(i) for i in range(65, 65+26)]:\n",
    "            os.makedirs(dirname_adv + c + \"/\" + c + \"→\" + d, exist_ok=True)\n",
    "\n",
    "\n",
    "    class ImageTransform():\n",
    "        def __init__(self, mean, std):\n",
    "            self.data_transform = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((64, 64)),\n",
    "            transforms.Normalize(mean, std)\n",
    "            ])\n",
    "\n",
    "        def __call__(self, img):\n",
    "            return self.data_transform(img)\n",
    "    mean = (0.5,)\n",
    "    std = (0.5,)\n",
    "    images_test = ImageFolder( \"../data/GoogleFonts/test\", transform = ImageTransform(mean, std))\n",
    "    batch_size = 1\n",
    "    test_loader = DataLoader(images_test, batch_size = batch_size, shuffle = False, drop_last=True)\n",
    "\n",
    "    # 精度カウンター\n",
    "    correct = 0\n",
    "    success = 0\n",
    "    # count = 0\n",
    "    count_list = [0] * 26\n",
    "\n",
    "    adv_examples = []\n",
    "    # i=0\n",
    "    a_list = []\n",
    "    # テスト用データセット内の全てのサンプルをループします\n",
    "    for data, target in tqdm(test_loader, total = 30862):\n",
    "\n",
    "        # データとラベルをデバイス（CPUもしくはGPU）に送信します\n",
    "        data, target = data.to(device), target.type(torch.LongTensor).to(device)\n",
    "        # テンソルの requires_grad 属性を設定します。攻撃者にとっては重要な設定です。\n",
    "\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # データをモデルに順伝播させます\n",
    "        output = model(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # 最大の確率のインデックスを取得します。\n",
    "\n",
    "        # 最初から予測が間違っている場合、攻撃する必要がないため次のイテレーションに進みます。\n",
    "        \n",
    "        if init_pred.item() != target.item() or target.item() != 0:\n",
    "            continue\n",
    "\n",
    "        correct += 1\n",
    "\n",
    "        data_copy = data.detach().clone()\n",
    "        # character_coordinate = character_search(data_copy.data[0][0])\n",
    "\n",
    "        count_list[init_pred.item()] += 1\n",
    "    \n",
    "        # 損失を計算します\n",
    "        loss = F.nll_loss(output, target)\n",
    "        # 既存の勾配を全てゼロにします\n",
    "        model.zero_grad()\n",
    "        # 逆伝播させてモデルの勾配を計算します\n",
    "        loss.backward()\n",
    "        # データの勾配を取得します\n",
    "        data_grad = data.grad.data\n",
    "        \n",
    "        # # 勾配のヒートマップ\n",
    "        # grad_map = data_grad.squeeze().detach().cpu().numpy()\n",
    "        # grad_map_abs = np.abs(grad_map)\n",
    "        # plt.xticks([], [])\n",
    "        # plt.yticks([], [])\n",
    "        # plt.imsave(dirname_grad + chr_lambda(init_pred.item()) + \"/{}.png\".format(count_list[init_pred.item()]), grad_map_abs, cmap=\"Reds\")\n",
    "\n",
    "        perturbed_data, pred, success = attack(data, data_grad, target, dirname_res, dirname_pro, chr_lambda(init_pred.item()), count_list[init_pred.item()], 0.001, 0, success)\n",
    "\n",
    "        final_pred = pred\n",
    "\n",
    "        org = data_copy.squeeze().detach().cpu().numpy()\n",
    "        adv = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "\n",
    "        #各条件を満たす画像の保存\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        plt.imsave(dirname_org + chr_lambda(init_pred.item()) + \"/{}.png\".format(count_list[init_pred.item()]), org, cmap=\"gray\")\n",
    "        \n",
    "        os.makedirs(dirname_adv + chr_lambda(init_pred.item()) + \"/\" + chr_lambda(init_pred.item()) + \"→\" + chr_lambda(final_pred.item()) + \"/\", exist_ok=True)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        plt.imsave(dirname_adv + chr_lambda(init_pred.item()) + \"/\" + chr_lambda(init_pred.item()) + \"→\" + chr_lambda(final_pred.item()) + \"/{}.png\".format(count_list[init_pred.item()]), adv, cmap=\"gray\")\n",
    "\n",
    "# print(success)\n",
    "# print(\"Test Accuracy = {} / 30862 = {}\".format(correct, correct / 30862))\n",
    "# print(\"Attack Success = {} / {} = {}\".format(success, correct, success / correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30862/30862 [34:43<00:00, 14.81it/s]  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADrCAYAAABXYUzjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAADfklEQVR4nO3YsW1CUQxA0f+ijAB1/v6zwBDUyQ5OjyiCBLkSnFNaLlzdwmtmNgD+30d9AMC7EmCAiAADRAQYICLAABEBBoh83rN8OBxm3/cnnQLwms7n88/MHK/ndwV43/ftdDo97iqAN7DWutyae0EARAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQWTPz9+W1vrdtuzzvHICX9DUzx+vhXQEG4HG8IAAiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiv24jG3fvmQi6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 各epsilonごとにテストを実行\n",
    "test(model, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
